\documentclass[twocolumn]{article}

\usepackage{graphicx}
\usepackage{biblatex}
\usepackage[spacing, tracking, kerning]{microtype}
\usepackage{fullpage}
\usepackage{titlesec}

\title{\bfseries Identifying Compiler Options to Minimize Energy Consumption for Embedded Platforms}
\author{James Pallister, Simon Hollis, Jeremy Bennett}

\titleformat{\section}{\Large\bfseries\centering}{}{0em}{}
\titleformat{\subsection}{\normalsize\bfseries}{}{0em}{}

\begin{document}
\maketitle
\section*{Abstract}

\textit{ABSTRACT}

\section*{Introduction}

% Talk about energy consumption in general
% energy consumption important
% many hardware features and optimizations (clock gating) to lower power consumption
% but cant be considered independently, software must be considered too, as it controls the hardware
Energy consumption is rapidly becoming one of the most important design constraints when writing software for embedded platforms. In the hardware space there have been many innovations for reducing the power consumption of electronic devices. However due to the software running on top of the hardware platform, the combination of software and hardware must be taken together when exploring energy usage.

% talk about embedded platforms
% lots of different architectures
% each has different energy consumption characteristics
Optimizing for low energy consumption is particularly important for embedded systems, where battery life is affected by the efficiency of the software. In these systems the processor is but one of the components consuming energy.

%GCC Talk compiler optimisations affecting performance.
%Many people think that this has been done, but no extensive data gathered on.
%Mention iterative compilation paper: only looked at 2 optimisations for 3 limited test cases. Want to know if faster program=less energy.
% not many studies with real hardware measurements
Compiler optimizations have the potential for energy savings with almost no changes to existing applications - just tweaking the compiler's parameters can have a large effect on the performance. This relationship is complex, with the program, processor's architecture and specific compiler options interacting together. Furthermore, different optimization passes interact with each other meaning that an option cannot be testing in isolation. A fractional factorial design method is used to construct the experiments when dealing with these interaction possibilities.

% hardware
All the energy measurements in this paper are taken using physical measurement circuitry attached to the processors. This avoids the use of models which could be inaccurate, or modelling an imaginary processor with no real world counterpart. By using commonly available platforms and processors along with some more novel architectures the results are more applicable while still providing insight into how different types of architectures perform. There are 5 platforms examined in this paper, shown in Table~\ref{Table:Platforms}.

\begin{table*}
	\begin{tabular}{l l l l l}
		\textbf{Board name} & \textbf{Processor} & \textbf{RAM} & \textbf{Speed} & \textbf{Extra} \\
		\hline
		STM32F0DISCOVERY	& ARM Cortex-M0 		& 8KB		& 48 MHz		  & 64KB Flash\\
		STM32VLDISCOVERY	& ARM Cortex-M3 		& 8KB		& 24 MHz		  & 128KB Flash\\
		BeagleBone			& ARM Cortex-A8 		& 256MB		& 500 MHz		  & VFP/NEON, superscalar\\
		EMEK3				& Adapteva E16 			& 32KB/core & 400 MHz		  & FPU, superscalar, 16 core NoC\\
		XK1					& XMOS L1 				& 64KB		& 100 MHz 		& 4$\times$100MHz hardware threads \\
	\end{tabular}
	\caption{The platforms explored in this paper along with some relevant details.}
	\label{Table:Platforms}
\end{table*}


%talk about power, aswell.
%less spikey power consumption,
%less overall power consumption = less bulky power supplies
For the embedded space, power consumption is also an issue. A lower power draw results in small circuitry for the power supply(REF),


%Talk about how different benchmarks are needed, taken from contempory, chosen to be implementable,
%short paragraph, quick justification.
A set of benchmarks has been derived from contemporary suites, chosen to be implementable on the target platforms. This set of 10 benchmarks (shown in Table~\ref{Table:Benchmarks}) covers real world and contrived applications coving different aspects of the target platform. The benchmarks cover combinations of the following criteria:
\begin{itemize}
	\setlength{\itemsep}{0em}
	% \setlength{\parskip}{1pt}
	\vspace{-1mm}
	\item \textbf{Integer pipeline intensity.} The frequency at which integer arithmetic instructions occur.
	\item \textbf{Floating point intensity.} The frequency of floating point operations.
	\item \textbf{Memory intensity.} This is whether the program requires a large amount of memory bandwidth or not.
	\item \textbf{Branch frequency.} This metric describes how often the code branches.
\end{itemize}


\begin{table}
\centering
	\begin{tabular}{l c c c c c c c l}
	\textbf{Name}			& \textbf{Source} 	& \textbf{Category} \\
	\hline
	crc32					& MiBench 	& network, telecomm	\\
	integer matmult			& WCET	 	& automotive	\\
	cubic root solver		& MiBench 	& automotive	\\
	2d fir					& WCET 		& automotive, consumer	\\
	float matmult			& WCET 		& automotive, consumer	\\
	dijkstra				& MiBench 	& network	\\
	blowfish				& MiBench 	& security	\\
	rjindael				& MiBench 	& security	\\
	sha						& MiBench 	& network, security	\\
	fdct					& WCET 		& consumer	\\
	\end{tabular}
\caption{Benchmarks selected, and the categories they fit into.}
\label{Table:Benchmarks}
\end{table}


% Briefly discuss what we do
% Using fractional factorial design
% Using a fractional factorial design the individual optimizations comprising each optimization level in GCC are analysed for their main and two-way interactions.
% This paper extensively evaluates possible optimizations available in GCC.

This paper covers the design and results of the experiment. First previous work in this space is discussed, along with the novel contribution this paper makes. After this the experimental design is discussed, followed by a brief description of the hardware setting. Then the experiments performed presented, with results. Finally the results are evaluated and the conclusions drawn are presented.

\section*{Previous work}

Mention not much previous work. Lots of work done on performance, and mostly assumed to carry over. Not much done with real hardware

Talk a lot about iterative compilation for energy paper. lack of benchmarks, only looks at loop unrolling and tilesize (todo check). The only tests they did were matrix multiplication, vector by matrix multiplication (and one more). Also only one architecture. The energy consumption might be very dependant on the architecture and way the pipeline is structured, so their results may not be applicable to other platforms.

performance==energy, only tested the overall optimization levels O1-O4 and 4 individual optimizations, simulated with wattch - inherits all the inaccuracies that wattch might have. the 4 individual optimizations are only applied individual, no exploration of the interactions between them is attempted. ar

what can the poor compiler do - most measurements on gatelevel sim. only one platform

\section*{Hardware Setup}

A few paragraphs about the hardware setup.
Talk about INA219, error bounds, analysis of error?
Talk about hooking the inductors

No OS

\section*{Experimental Design}

GCC has over 150 different option that can be enabled to control optimizations. The majority of these options are binary - the optimization pass is either enabled or disabled. To further complicate matters, an optimization path may be affect by other passes happening before it. As it is infeasible to test all possible combinations of options, a trade-off can be made. Using a fractional factorial design (FFD), adequate data can be gathered with a much reduced set of runs. This approach has been explored before in INTEL PAPER, where 9 optimizations were explored in just 35 tests as opposed to the 512 required for a full factorial design.

The drawback to this approach is that the high-order interactions between options will not be discernible. Fortunately this is not usually a problem as these types of interactions are statistically rare (REF?). The degree to which this happens is specified by the FFD's resolution (REF BOXHUNTER). A resolution 5 design ensures that the main effects are not aliased with anything lower than 4th order interactions.

Using the Yates algorithm the effect for any single or combination of factors can be found from the data. This gives an average estimation for how much this factor or interaction affects the result of the experiment

% This section outlines the fractional factorial design (FFD) method used in this paper.

% Fractional Factorial design. Mention intel paper

% Quick overview of how FFD works. Introduce resolutions, mention that compiler options should possible have many highorder interactions

All FFDs used were generated by R, using the FrF2 library (REF).

\section*{Compiler Options Examined}

talk about the experiments we actually did

For each platform and benchmark combination the following experiments were ran.

\subsection*{First Optimization Level (O1)}

A FFD design of resolution 5 was used to evaluate GCC's 37 flags turned on by \texttt{-O1}. This consisted of 2048 different runs, allowing the main factors to be examined. If third order interactions are considered negligible, two way interactions of the flags can be resolved. The experiment aimed to identify which of the flags in this optimization level has the largest

\subsection*{Second Optimization Level (O2)}

As with the \texttt{O1} experiment this uses a resolution 5 FFD to examine the 36 factors enabled by \texttt{-O2}. This optimization level enables more advanced optimizations, such as instruction scheduling an various peephole optimizations.

\subsection*{Third Optimization Level (O3)}

As with the previous two experiments this uses an FFD to examine the 9 factors enabled by \texttt{-O3}. This optimization level enables the most aggressive optimizations typically used, including optimizations that increase performance at the expense of code size.

\subsection*{Incremental Tests}

This experiment used to data generated by the \texttt{O1} tests to cumulatively turn on the flags in order of best to worst. When compared to having all the flags on those shows the effect that a small number of optimisations can have on the code.

\subsection*{Single Flag Difference}

This experiment enabled the first optimization level (\texttt{-O1}) then individually added or subtracted possible optimisation flags. The aim of this experiment was to identify if a single flag could have a significant difference on the energy consumption.

\subsection*{Profiling}

Using profile guided feedback the compile can make much better guesses about what the code is going to do. This allows extra optimizations to be enabled and improves to performance of some existing optimizations.

\subsection*{Link Time Optimization}

When the benchmark consists of multiple compilation units, the program is not optimized as a whole. This means many of the optimizations performed could be better if done at link time.

\section*{Results}

Basic results table, matrix - columns are platforms, rows are benchmarks, O0, O1, O2, O3 results in each cell?
Could have a small 4 point line graph in each cell, percentage improvement over baseline (O0)

present interesting graphs

\subsection*{Time and Energy}

mostly true.
some cases when not the case. why is this?
suggest in some cases, without changing performance you can reduce energy

talk when arent the same.
reasons for that

% talk about what the results are briefly
% second and third order interactions

count
by eye add up significant factors, how many times occur across benchmark, platform
generality - specific to benchmarks or

point some option good or bad, cant really predict
exhaustive search

\section*{Modelling}

Talk about how the FFD can be used to predict what flags are good

\section*{Comparison with LLVM}

Just O1, O2, O3


\section*{Evaluation}

Talk about error
 - hardware measurement
 - total amonut of energy used is correct, even if sample rate is low
 - FFD
 - cold start problem
 	only affects beaglebone, as no caches otherwise, but fits in cache anyway


Draw correlations between platforms and benchmarks.

See if there is any correlation between the `execution characteristics' of the benchmark and the flags that affect it.

Can we propose a set of options that on average performs better for the benchmarks?

Why did we get these results


\section*{Conclusion}

\section*{Future Work}

\printbibliography

\end{document}
