\documentclass[twocolumn]{article}

\usepackage{graphicx}
\usepackage[doi=false,url=false,isbn=false]{biblatex}
\usepackage[spacing, tracking, kerning]{microtype}
\usepackage[top=1in, bottom=1in, left=0.8in, right=0.8in]{geometry}
% \newcommand{\subparagraph}{}
\usepackage{titlesec}
\usepackage{float}
\usepackage{color}
\usepackage[usenames,dvipsnames,svgnames,table]{xcolor}
\usepackage{placeins}
% \usepackage{dblfloatfix}
% \usepackage{fixltx2e}
\usepackage[bottom]{footmisc}
% \usepackage{kpfonts}
\usepackage{amsfonts}
\usepackage{relsize}
\newcommand{\tY}{\checkmark}
\newcommand{\tN}{$\times$}

% \usepackage{caption}
% \usepackage{subcaption}

% \usepackage{fontspec}
% \setmainfont{Humor Sans}

\bibliography{refs}

\graphicspath{{./images/}}

\title{\bfseries\fontsize{22}{1}\selectfont Identifying Compiler Options to Minimize Energy Consumption for Embedded Platforms}
\author{James Pallister, Simon Hollis, Jeremy Bennett}

\titleformat{\section}{\Large\bfseries\centering\scshape}{}{0em}{}
\titleformat{\subsection}{\normalsize\bfseries}{}{0em}{}

\newcommand{\nsection}[1]{\section{\bfseries #1}}

\newcommand{\superscript}[1]{\ensuremath{^{\textrm{#1}}}}
\newcommand{\todo}[1]{\textbf{\textcolor{red}{#1}}}

% \let\oldcite\cite
% \renewcommand{\cite}[1]{\textsuperscript{\oldcite{#1}}}

\let\oldcaption\caption
\renewcommand{\caption}[1]{\oldcaption{\textup{#1}}}

\begin{document}
\maketitle
\begin{table*}[!hbt]
	\centering
	\begin{tabular}{l l l l l}
		\textbf{Board name} & \textbf{Processor} & \textbf{RAM} & \textbf{Speed} & \textbf{Extra} \\
		\hline
		STM32F0DISCOVERY	& ARM Cortex-M0 		& 8KB		& 48 MHz		  & 64KB Flash\\
		STM32VLDISCOVERY	& ARM Cortex-M3 		& 8KB		& 24 MHz		  & 128KB Flash\\
		BeagleBone			& ARM Cortex-A8 		& 256MB		& 500 MHz		  & VFP/NEON, superscalar\\
		EMEK3				& Adapteva E16 			& 32KB/core & 400 MHz		  & FPU, superscalar, 16 core NoC\\
		XK1					& XMOS L1 				& 64KB		& 100 MHz 		& 4$\times$100MHz hardware threads \\
	\end{tabular}
	\caption{The platforms explored in this paper along with some relevant details.}
	\label{Table:Platforms}
\end{table*}

\section{Abstract}

{\bfseries
This paper uses an innovative technique to explore the effect on energy consumption of 87 optimizations GCC performs when compiling 10 benchmarks for five different embedded platforms. Hardware power measurements on each platform are taken to ensure all architectural effects on the energy are captured. A fractional factorial design is used to separate the effects of each optimization and account for interactions between optimizations. We find that in the majority of cases execution time and energy consumption are highly correlated, but the effect a particular optimization may have is non-trivial due to its interactions with other optimizations. Also it is noticed that the structure of the benchmark has a larger effect than the platform on whether the optimization will be effective, and no one optimization is universally positive for run-time or energy consumption.
}

\section{Introduction}


% Talk about energy consumption in general
% energy consumption important
% many hardware features and optimizations (clock gating) to lower power consumption
% but cant be considered independently, software must be considered too, as it controls the hardware
Energy consumption is rapidly becoming one of the most important design constraints when writing software for embedded platforms. In the hardware space there have been many features such as clock gating to reduce the power consumption of electronic devices. However, due to the software controlling the underlying hardware platform, a combination of software and hardware must be taken together when exploring energy usage.

% talk about embedded platforms
% lots of different architectures
% each has different energy consumption characteristics
%talk about power, aswell.
%less spikey power consumption,
%less overall power consumption = less bulky power supplies
Optimizing for low energy consumption is particularly important for deeply embedded systems, which may have to adhere to a strict power budget. In these systems the processor is but one of the components consuming energy. A previous study characterized the CPU power usage of a mobile phone to be between 10 and 20\% of the total system power\cite{SmartPhonePower}. As the radio consumes roughly 50\% of the power in this system, it can be seen in systems without the GSM component the processor takes a non-trivial proportion of the power.

 % previous studies have established that the processor takes between 20\% and 40\% of the overall system power \todo{Find a reference for this? is this true?} For the embedded space, power consumption is also an issue. A lower power draw results in small circuitry for the power supply\todo{(REF)}.

%GCC Talk compiler optimisations affecting performance.
%Many people think that this has been done, but no extensive data gathered on.
%Mention iterative compilation paper: only looked at 2 optimisations for 3 limited test cases. Want to know if faster program=less energy.
% not many studies with real hardware measurements
Compiler optimizations have the potential for energy savings with no changes to existing applications --- just tweaking the compiler's parameters can have a large effect on the performance. This relationship is complex, with the program, processor architecture and specific compiler options interacting together. Furthermore, different optimization passes interact with each other meaning that an option's efficacy cannot be tested in isolation. For example, inlining a function may mean that more effective common expression elimination can be performed, reducing the instruction count more than either option individually. There have been many approaches attempted to solve this problem\cite{Haneda2005, Lin2008, Triantafyllis}. These studies look at various statistical methods and genetic algorithms to select optimizations. All of these studies conclude that performance can be gained from choosing the correct set of optimizations but exploring the space to find this set is challenging.

This paper performs an advanced analysis that attempts to separate out the main effect the optimizations have from their interactions with other optimizations. These measurements are taken for a wide variety of optimization groupings, across five different platforms. We manage to assign an average effect to each optimization, enabling us to see which optimizations significantly affect the energy consumption. Each experiment we perform targets the set of optimizations enabled at a different optimization level, and overall this allows them to be sorted into three categories: decreases energy consumption, has no effect at all, or increases energy consumption.

% hardware
All the energy measurements in this paper are taken using physical measurement circuitry attached to the processors. This avoids the use of models which could be inaccurate, or modelling synthetic processors with no real world counterpart. By using commonly available platforms and processors along with some more novel architectures, the results are applicable in general while still providing insight into how different types of architectures perform. There are five platforms examined in this paper, shown in Table~\ref{Table:Platforms}.

This paper covers the design and results of the experiments. First, previous work in this space is discussed, along with the novel contribution this paper makes. After this, the approach and a brief discussion of fractional factorial design is listed. Then, the experiments performed presented with results. Finally, the results are evaluated and the conclusions drawn are presented.


\begin{table}[t]
	\centering
	\begin{tabular}{l c l}
	\textbf{Name}			& \textbf{Source} 	& \textbf{Category} \\
	\hline
	2D FIR					& WCET 		& automotive, consumer	\\
	Blowfish				& MiBench 	& security	\\
	CRC32					& MiBench 	& network, telecomm	\\
	Cubic solver			& MiBench 	& automotive	\\
	Dijkstra				& MiBench 	& network	\\
	FDCT					& WCET 		& consumer	\\
	Float matmult			& WCET 		& automotive, consumer	\\
	Int matmult				& WCET	 	& automotive	\\
	Rjindael				& MiBench 	& security	\\
	SHA						& MiBench 	& network, security	\\
	\end{tabular}
\caption{Benchmarks selected, and the categories they fit into. These are selected from MiBench\cite{MiBench} and the Worst Case Execution Time (WCET)\cite{WCET} suites.}
\label{Table:Benchmarks}
\end{table}

% Briefly discuss what we do
% Using fractional factorial design
% Using a fractional factorial design the individual optimizations comprising each optimization level in GCC are analysed for their main and two-way interactions.
% This paper extensively evaluates possible optimizations available in GCC.

\section{Previous work}

% Mention not much previous work. Lots of work done on performance, and mostly assumed to carry over. Not much done with real hardware
To date there has been very little work extensively exploring the effect that different compiler optimizations have on energy consumption. Most studies focus on only a few optimizations in isolation, and few consider multiple platforms with different architectural features. Commonly explored optimizations such as loop unrolling, inlining and instruction scheduling have been examined extensively for different platforms, using both simulators and hardware measurements\cite{EffectOfCompilerOptimizationsOnPentium4}.

% TODO talk about wattch, physical measurements better? looking for interesting results, as wattch is just an abstraction they may be missed. only used in one configuration mostly, energy could be very dependent on pipeline.
Many papers discussing energy choose to use the Wattch simulator\cite{Wattch}, designed to allow easy energy measurements for a variety of configurations. The accuracy of Wattch is established at being within 10\% of an industry layout-level power tool. However, when simulating a program with a single optimization pass turned on, the effects may be small enough to be mistaken for error when using the Wattch framework.

SimplePower\cite{SimplePower} is another simulator that has been used to explore the effects of the software running on a processor. This simulator targets a five stage RISC pipeline, with models estimating the energy consumption based on the number of transitions on bus signal lines as well as various other components.

Various other models have been created to simulate power consumption of the processor\cite{Park2011,Schneider2005}. These all suffer the drawback that some of the energy consumption effects may not be modelled, potentially skewing the results.

% Talk a lot about iterative compilation for energy paper. lack of benchmarks, only looks at loop unrolling and tilesize (todo check).
%The only tests they did were matrix multiplication, vector by matrix multiplication (and one more).
%Also only one architecture (wattch).
%The energy consumption might be very dependant on the architecture and way the pipeline is structured, so their results may not be applicable to other platforms.
Iterative compilation has been examined as a possibility for choosing optimizations that reduce power by Gheorghita, Corporaal and Basten\cite{IterativeCompilationForEnergy}. In this paper, the effect of different loop unrolling and loop tiling parameters on energy consumption was examined for three benchmarks --- all matrix-based benchmarks. The energy consumption was estimated using the Wattch simulator as opposed to taking hardware measurements. They came to the conclusion that iterative compilation was an effective method of decreasing energy consumption as well as improving performance.

%However iterative compilation does not account for interactions between the optimization passes which could potentially have N! combinations to explore.

A similar study conducted by Patyk et al\cite{EnergyReductionCompilerOptions}, explored a range of GCC's options, with an aim to reduce energy consumption by identifying significant optimizations then excluding them from further exploration. While this does reduce the masking effect that a significant optimization can have, due to the vast number of interactions between compiler options, the flag may not have the same effect when combined with other optimizations. We try to rectify this by using fractional factorial designs.

Fractional factorial design, as a method for exploring the interactions of compiler optimizations was explored in the paper `Feedback-Directed Selection and Characterization of Compiler Optimizations'\cite{IntelPaper}. Nine optimizations were examined, using a fractional factorial technique to isolate the interactions and choose a set of optimizations that gave better performance then just turning all the optimizations on.

The MILEPOST GCC study implemented one alternative to compiling a program many times by using machine learning to guess which optimization flags would best apply to a given program. Features are extracted from the program, which are then matched against previous known results from previous compilations. This allows a set of optimizations to be estimated from just the source code.

% performance==energy, only tested the overall optimization levels O1-O4 and 4 individual optimizations, simulated with wattch - inherits all the inaccuracies that wattch might have. the 4 individual optimizations are only applied individual, no exploration of the interactions between them is attempted. ar
The topic of performance and energy being highly correlated is addressed in `Is Compiling for Performance == Compiling for Power?'\cite{CompilingForPerformancePower}. The paper explored several different overall optimization levels, as well as four specific optimizations, also using the Wattch simulator to gather energy results. However the specific optimizations were all applied individually on top of \texttt{-O1}, without exploring any possible interactions between the optimizations. The main conclusion drawn from this study was that most optimizations reduce the number of instructions executed, hence reducing energy consumption and execution time simultaneously.

% compilation techniques for low energy
% identified that the following could be used by compilers to reduce energy:
% 	reordering to reduce switching
% 	reducing memory accesses
% 	improving cache hits
% 	reduce switching on address lines
% 	improve page hits
An analysis of the techniques the compile can perform to optimize for energy was carried out by Tiwari, Malik and Wolfe\cite{CompilationTechniquesForLowEnergy}. They identified several possible techniques that compilers could use to reduce the energy consumption of programs:
\begin{itemize}
	\setlength{\itemsep}{0em}
	\vspace{-1mm}

	\item Reorder instructions to reduce switching.
	\item Reduce switching on address lines.
	\item Reduce memory accesses.
	\item Improve cache hits.
	\item Improve page hits.
\end{itemize}

It is expected that optimizations that cover some of these points will have an effect on energy. The last three will also normally increase performance as well as reduce energy.

% what can the poor compiler do - most measurements on gatelevel sim. only one platform
Another paper attempts to classify the effect optimizations can have on performance and energy\cite{WhatCanAPoorCompilerDo}. This paper took a both hardware measurements and used a gate-level simulation to derive the results,  separating the optimizations into three classes:
\begin{itemize}
	\setlength{\itemsep}{0em}
	\vspace{-1mm}
	\item Reduction in energy consumption due to increase in performance. These optimizations reduce the number of cycles or instructions needed to complete the application and thus less overall work is done because.
	\item Optimizations that reduce energy while not improving the performance. Scheduling instructions to reduce switching often falls into this category.
	\item Optimizations that increase energy consumption or performance. These would typically be bad optimizations to choose.
\end{itemize}

% \textcolor{blue}{One of our contributions is to show a fourth category exists: optimizations that increase energy consumption while increasing performance. This is in opposition to the second category listed above.}

Architectural modifications to embedded processors have been proposed as a way to save energy. Guan and Fei investigated partitioning the register file\cite{RegisterFilePartitioning} into hot and cold regions to save energy. Registers were reallocated after compilation to enhance the benefit of this technique. Another modification possible is changing the instruction encoding to minimize switching between consecutive instructions. This was examined in `Low-Power Instruction Encoding Techniques'\cite{LowPowerInstructionEncodings} and shown to greatly minimize bit-switching between instruction op-codes.

Several novel types of compiler optimizations have been proposed. Seth et al.\cite{Seth2001} explored the possibility of using the compile to insert \texttt{idle} instructions automatically, increasing the execution time up to a set limit. Using the SIMD pipeline been shown to decrease energy consumption\cite{Ibrahim2009} by roughly 25\%. Scheduling instructions to minimize the inter-instruction energy cost was evaluated to be another effective method to reduce a programs energy consumption\cite{Parikh}.


\section{Approach}

The majority of the studies listed previously only examine one platform, and it is currently unknown whether the results would apply across multiple different platforms. Furthermore, the iterative compilation and other adaptive techniques used can leave holes of potential combinations of optimizations unexplored (due to the huge numbers of combinations possible). This could lead to the most optimal configurations not being found. In this paper we present another technique for testing the effectiveness of large numbers of compile optimization flags and their impact on energy consumption and run-times. The technique is based on the concept of fractional factorial designs (discussed in the following section).

%Talk about how different benchmarks are needed, taken from contempory, chosen to be implementable,
%short paragraph, quick justification.
A set of benchmarks has been derived from contemporary suites, chosen to be implementable on the target platforms. This set of 10 benchmarks (shown in Table~\ref{Table:Benchmarks}) covers real world and synthetic applications across different aspects of the target platform. The benchmarks cover combinations of the following criteria:
\begin{itemize}
	\setlength{\itemsep}{0em}
	% \setlength{\parskip}{1pt}
	\vspace{-1mm}
	\item \textbf{Integer pipeline intensity.} The frequency at which integer arithmetic instructions occur.
	\item \textbf{Floating point intensity.} The frequency of floating point operations.
	\item \textbf{Memory intensity.} This is whether the program requires a large amount of memory bandwidth or not.
	\item \textbf{Branch frequency.} This metric describes how often the code branches.
\end{itemize}

These benchmarks were constructed to run on the `bare metal' --- no host OS needed. This prevents the benchmark from being pre-empted by an operating system performing a background task and reducing the accuracy of the results.


In this paper we explore the impact of compiler optimizations using the GCC toolchain on the architectures in Table~\ref{Table:Platforms}. GCC exposes its various optimizations via a number of flags that can be passed to the compiler. We explore what flags are and are not significant for energy consumption and execution time.

\section{Fractional Factorial Design}

GCC has over 150 different options that can be enabled to control optimizations. The majority of these options are binary --- the optimization pass is either enabled or disabled. To further complicate matters, an optimization path may be affected by other passes happening before it. As it is infeasible to test all possible combinations of options, a trade-off can be made. One of our main contributions is to deploy fractional factorial design (FFD) to massively reduce the exploration space, whilst still identifying the options in the set that contribute to run-time and energy. This approach has been explored before in `Feedback-Directed Selection and Characterization of Compiler Optimizations'\cite{IntelPaper}, where nine optimizations were explored in just 35 tests as opposed to the 512 required for a full factorial design.

The drawback to this approach is that the high-order interactions between options will not be discernible. Fortunately this is not usually a problem as these types of interactions are statistically rare. The degree to which this happens is specified by the FFD's resolution. A resolution 5 design ensures that the main effects are not aliased with anything lower than 4th order interactions.

Using the Yates algorithm\cite{BoxHunter} the effect for any single or combination of factors can be found from the data. This gives an average estimation for how much this factor or interaction affects the result of the experiment

% This section outlines the fractional factorial design (FFD) method used in this paper.

% Fractional Factorial design. Mention intel paper

% Quick overview of how FFD works. Introduce resolutions, mention that compiler options should possible have many highorder interactions

All FFDs used were generated by R\cite{R}, using the FrF2 library\cite{FrF2}.

\subsection*{Optimized Flow}

We now propose an optimization to the basic FFD flow, which stems from the observation from an initial pass, that a large number of options have no effect on the output. The steps below detail an optimized flow for using fractional factorial designs efficiently.
\begin{enumerate}
	\setlength{\itemsep}{0em}
	\vspace{-1mm}
	\item A very quick `screening design' can be performed to obtain a rough idea of the main factors affecting the design. This could be implemented using a Plackett-Burman design\cite{Bose1940}, allowing $N$ factors to be efficiently explored in $N+1$ runs.
	\item The factors who's main effect is close to zero can be excluded. The threshold set here for excluding factors will determine how many runs the subsequent step needs.
	\item Using the subset of factors, a more comprehensive FFD can be run to resolve the higher order interactions.
\end{enumerate}

For example, if the test shown in Figure~\ref{Fig:BlowfishMainEffects} was rerun following this procedure, all of the factors in the middle, below 0.2\% could be excluded, reducing the number of factors from 37 down to 15. An FFD could then be constructed with these 15 factors:

\begin{center}
\begin{tabular}{l r r}
	& \multicolumn{2}{c}{Runs needed for $N$ factors} \\
	Resolution & \hspace{5mm}$N=37$ & $N=15$ \\
	\hline
	3 & 256	   & 16 \\
	4 & 1024   & 32 \\
	5 & 2048   & 256 \\
	6 & 4096   & 512 \\
\end{tabular}
\end{center}

%Result graph here for better placement
\begin{figure*}[tb!]
	\centering
	\includegraphics[width=\textwidth,clip, trim=0cm 0cm 0 2.1cm]{levels.pdf}
	\caption{Energy, Time and Power results for benchmark-platform combinations. Optimization levels \texttt{O0} to \texttt{O3}.}
	\label{Fig:OverallView}
\end{figure*}

\section{Experimental Design}

This section talks about the individual experiments that were run on the hardware. For each platform and benchmark combination the following experiments were carried out. The majority of compilers come with pre-bundled collections of flags: generally the optimization levels \texttt{-O1}, \texttt{-O2} and \texttt{-O3}. The increasing numbers indicate how much optimization is done on the target. These bundles contain options that reduce the performance in some case, so to find an optimal set the optimizations in the bundle have to be examined.

\subsection*{First Optimization Level (\texttt{O1})}

An FFD design of resolution 5 was used to evaluate GCC's 37 flags turned on by \texttt{-O1}. This consisted of 2048 different runs, allowing the main factors to be extracted. If third order interactions are considered negligible, two way interactions of the flags can be resolved. The experiment identifies which of the flags in this optimization level has the largest impact on energy consumption and execution time.

\subsection*{Second Optimization Level (\texttt{O2})}

As with the \texttt{O1} experiment this uses a resolution 5 FFD to examine the 36 factors enabled by \texttt{-O2}. This optimization level enables more advanced optimizations, such as instruction scheduling and various peephole optimizations.

\subsection*{Third Optimization Level (\texttt{O3})}

As with the previous two experiments this uses an FFD to examine the 9 factors enabled by \texttt{-O3}. This optimization level enables the most aggressive optimizations typically used, including optimizations that increase performance at the expense of code size.

% \subsection*{Incremental Tests}

% This experiment used to data generated by the \texttt{O1} tests to cumulatively turn on the flags in order of best to worst. When compared to having all the flags on those shows the effect that a small number of optimisations can have on the code.

\subsection*{Single Flag Difference}

This experiment enabled the first optimization level (\texttt{-O1}) then individually added or subtracted possible optimization flags. The aim of this experiment was to identify if a single flag could have a significant difference on the energy consumption.

\section{Hardware Setup}

All the measurements were taken using the INA219 power monitoring IC\cite{INA219}, which provides power, current and voltage outputs. This chip measures the voltage drop across a small shunt resistor inline with the target circuit. For all platforms this is placed after the voltage regulator, before the main processor. Each INA219 chip is connected the an XMOS controller board to record the results and transfer them to the host PC. Each platform has a GPIO line connected to the controller which is used to identify when the benchmarks start and end, allowing just the intended portion of the benchmark to be measured (ignoring any extra initialization code).

The Cortex-M0 and Cortex-M3 boards both have a single measurement point, recording the power consumed by the whole microprocessor. For the BeagleBone there are three available measurement points: the Cortex-A8 core, on-chip peripherals (caches, power management) and the external SDRAM memory IC. This allows the effect of the compiler optimizations on the memory to be recorded. Adapteva's Epiphany board has two measurement points: the core power consumption and IO power consumption, whereas the XMOS board's measurement point gathers power consumption data for the core of the processor.

\section{Results}

\begin{figure}[t]
	\includegraphics[width=\linewidth,clip,trim=0.5cm 0 2cm 1.8cm]{cortex-a8/O3_main_effects_2dfir.pdf}
	\caption{2D FIR benchmark on the Cortex-A8 platform. Individual options enabled at \texttt{O3} are listed.}
	\label{Fig:O3_2dfir_A8}
\end{figure}


\subsection*{Time and Energy}

This study aims to establish whether execution time and energy consumption are highly correlated in the majority of cases. This hypothesis underlies many of the assumptions of the energy-efficiency community relating to the best way forward in producing energy-efficient software. Overall it was found that this hypothesis is correct, with some small divergences for the Cortex-A8. This platform has superscalar execution (thus reducing execution time more than energy) and NEON SIMD instructions (possibly reducing energy more than execution time). This section presents the results supporting this conclusion, and discusses some of the cases where there is a difference between energy consumption and execution time.

A high level overview of each platform and benchmark for different optimization levels is given in Figure~\ref{Fig:OverallView}. This figure shows a small line graph for each combination, displaying the effect of the broad optimization levels \texttt{O1}, \texttt{O2}, \texttt{O3} and \texttt{O4} (\texttt{O3} with link time optimization) on time, energy and power.

\begin{figure}[t]
	\includegraphics[width=\linewidth,clip,trim=0.5cm 0 2cm 1.8cm]{cortex-m0/O1_main_effects_blowfish.pdf}
	\caption{Blowfish benchmark on the Cortex-M0 platform. Individual options enabled at \texttt{O1} are listed.}
	\label{Fig:BlowfishMainEffects}
\end{figure}

\begin{table}
	\centering
	\begin{tabular}{c p{0.3\linewidth} p{0.4\linewidth}}
		\bfseries NEON & \bfseries Instruction Dependencies & \bfseries Continuous Power Consumption \\
		\hline
		No & \centering Yes & {\hspace{0.85cm} 168000 uW } \\
		No & \centering No & {\hspace{0.85cm} 195000 uW } \\
		Yes & \centering Yes & {\hspace{0.85cm} 158000 uW } \\
		Yes & \centering No & {\hspace{0.85cm} 159000 uW } \\
	\end{tabular}
	\caption{Micro-benchmark results for multiplications on the NEON unit, with and without inter-instruction dependencies.}
	\label{Table:SIMD}
\end{table}

There is very little divergence in the platforms with `simple' pipelines --- energy and execution time are highly correlated. This is due to the nature of the pipeline: there is little scope for instruction level parallelism and complex instruction scheduling. For these devices, simply reducing the total number of instructions executed reduces the energy accordingly. The opposite is seen with the Cortex-A8's much more complex pipeline: its energy consumption profile becomes more complex.

Further results showing the correlation between time and energy are shown in Figure~\ref{Fig:BlowfishMainEffects}. This shows the main effect each optimization has on the runtime and energy consumption, as calculated by the FFD.

Figure~\ref{Fig:FdctO2MainEffects} highlights a discrepancy that occurred between execution time and energy consumption, even for very similar optimizations. The first two options listed (\texttt{-fschedule-insns} and \texttt{-fschedule-insns2}) both schedule instructions to reduce instruction stalls. However the latter option performs its scheduling pass after register allocation, where as the first performs it before. In this case scheduling before the register allocation reduces the energy consumption by much more than the execution time.

For the cubic benchmark there is a much smaller performance gain from the optimizations than with the other benchmarks. This is due to the main computational body of work being done by the precompiled libraries providing the trigonometric functions.

\subsection{Architectures and their Effects}

The following paragraphs explore the architectural details of the processors, and how they are connected to the energy consumption.

For the Cortex-M0, very little difference between energy and time is seen due to it being the simplest processor tested: it has a three stage pipeline without forwarding logic. The pipeline never stalls unless it encounters a load, in which case it always stalls. The Cortex-M3 exhibits very similar behavior, with some very slight differences between energy and time. The microarchitecture in this processor is more complex, featuring branch speculation and a larger instruction set\cite{Yiu2010}.

The XMOS processor has a four stage pipeline, similar to the Cortex-M3 in complexity and performance. It should also be noted that the compiler for the XMOS processor uses an LLVM backend for code generation, featuring different optimizations. Due to this the result set for this processor is not as extensive as the other four.

\begin{figure}[bt!]
	\includegraphics[width=\linewidth,clip,trim=0.5cm 0 2cm 1.8cm]{cortex-m3/O2_main_effects_fdct.pdf}
	\caption{FDCT benchmark on the Cortex-M3 platform. Individual options enabled at \texttt{O2} are listed.}
	\label{Fig:FdctO2MainEffects}
\end{figure}

The Epiphany processor also sees a large correlation between the energy consumption and execution time. There is some divergence for a few of the benchmarks. These are likely when the superscalar core in the processor has been able to dispatch multiple instructions simultaneously.

The greatest difference between energy and time was using the Cortex-A8. For the majority of the benchmarks the execution time reduces more than the energy. This is due to multiple instructions being executed simultaneously by the core, reducing the amount of time taken but not the energy consumption, as the same total work is still being done. The gap is also seen to widen at the \texttt{O2} level, due to instruction scheduling being enabled there.

\subsection{Efficient SIMD Units}

An interesting effect is seen in 2dfir for this processor. The execution time decreases more than the energy consumption up to \texttt{O2}, but when enabling \texttt{O3} the energy decreases more than the execution time. On further investigation of this \texttt{O3} enables two options that have a significant effect on the energy (shown in Figure~\ref{Fig:O3_2dfir_A8}):
\begin{itemize}
	\item \texttt{\bfseries -fgcse-after-reload}. This option enables an extra pass to eliminate redundant loads after spill code has been generated.
	\item \texttt{\bfseries -ftree-vectorize}. This option vectorizes loops so that SIMD instructions can be used.
\end{itemize}

Further investigation of the NEON SIMD unit was done using some small micro-benchmarks. The results of these are shown in Table~\ref{Table:SIMD}, showing for multiplication the NEON unit uses a lot less power than using the normal Cortex-A8 multiplier.

\subsection{Optimization Chaos}

\begin{figure*}[bt]
	\includegraphics[width=\linewidth,clip,trim=0.5cm 0 0cm 1.8cm]{cortex-m3/O1_addsub_blowfish.pdf}
	\caption{Blowfish benchmark on the Cortex-M3 platform. Individual options are enabled or disabled on top of the \texttt{O1} optimization level.}
	\label{Fig:AddsubO1Blowfish}
\end{figure*}

A further conclusion of this study is of the difficulty in predicting the effectiveness of an optimization. This section presents a case stufy where optimization flags are seen to affect energy chaotically. 

Examining the correlation between optimizations and their effects is a complex issue. Due to non-linear interactions, one would expect that the prediction of effects is difficult. This is borne out by our experimental results: as seen in previous figures~\ref{Fig:BlowfishMainEffects} and~\ref{Fig:FdctO2MainEffects}, less than a third of the options have a significant impact. For the other optimizations, higher order interactions cause unpredictable effects, where enabling or disabling a particular optimization can completely change the effect of many other subsequent optimization passes.

In Figure~\ref{Fig:AddsubO1Blowfish}, several unexpected effects worthy of further investigation can be seen. This graph shows individual optimizations being turned on and off, using the \texttt{O1} optimization level as a base. The flags on the left of the \texttt{O1} section were found to decrease the energy consumption when disabled, an effect not seen in the FFD results. These flags were chosens for futher exploration.

To explore the unpredictability, a small case study was performed, where all combinations of four options were explored. The energy figures for exhausive exploration can be seen in Table~\ref{Table:Exhaustive}, with the aim being to ascertain whether the effect of this energy reduction would compound with multiple flags. The \texttt{O1} column of this table shows the results when the options were applied on top of the \texttt{O1} optimization level. The \texttt{O2} column shows the same but on top of the \texttt{O2} optimization level.

From the \texttt{O1} column this it can be seen that there are many interactions occurring between the options, as simply turning all of these options off does not decrease the energy (in fact it increases the consumption by 1.81\%). Furthermore, when disabled individually, \texttt{-fguess-branch-probability} and \texttt{-ftree-dominator-opts} decrease the energy by 2.49\% and 1.76\% respectively. However when both enabled, the energy consumption (relative to \texttt{O1}) is only 0.93\% less ---s worse than each flag individually.

Different results are seen entirely in the \texttt{O2} column, with options that decreased energy consumption on top of \texttt{O1} have little or the opposite effect when applied on top of \texttt{O2}.

This unpredictability suggests that these options have many interdependencies that are difficult to predict upfront. It also makes choosing an optimal set of optimizations very challenging. Therefore, one of our findings is that it is very unlikely any accurate prediction mechanism for considering an optimization and its effect on a target system exists. The effect will always be highly dependent on the application to be used ant the platform upon which it resides.

\begin{table}[tb]
	\centering
	\begin{tabular}{c c c c c r@{.}l c r@{.}l }
		& & & \multicolumn{3}{c}{\hspace{1.5cm}\bfseries \texttt{O1}} & \multicolumn{3}{c}{\hspace{1.3cm}\bfseries \texttt{O2}} \\
		\bfseries X1 & \bfseries X2 & \bfseries X3 & \bfseries X4 & \bfseries (mJ) 	 & \multicolumn{2}{c}{\bfseries (\%)} &
		\bfseries (mJ) 	 & \multicolumn{2}{c}{\bfseries (\%)} \\
		\hline
		\tY&\tY&\tY&\tY& 5779 & 0&00 	&  5483 &  0&00\\
		\tN&\tY&\tY&\tY& 5635 & -2&49 	&  5538 &  1&00\\
		\tY&\tN&\tY&\tY& 5677 & -1&76 	&  5480 & -0&05\\
		\tN&\tN&\tY&\tY& 5725 & -0&93 	&  5619 &  2&49\\
		\tY&\tY&\tN&\tY& 5647 & -2&28 	&  5487 &  0&09\\
		\tN&\tY&\tN&\tY& 5723 & -0&97 	&  5579 &  1&75\\
		\tY&\tN&\tN&\tY& 5611 & -2&90 	&  5481 &  -0&03\\
		\tN&\tN&\tN&\tY& 5644 & -2&33 	&  5529 &  0&85\\

		\tY&\tY&\tY&\tN& 5759 & -0&34 	&  5459 &  -0&43\\
		\tN&\tY&\tY&\tN& 5716 & -1&09 	&  5484 &  0&03\\
		\tY&\tN&\tY&\tN& 5863 & 1&45 	&  5491 &  0&15\\
		\tN&\tN&\tY&\tN& 5957 & 3&08 	&  5483 &  0&00\\
		\tY&\tY&\tN&\tN& 5889 & 1&91 	&  5472 &  -0&19\\
		\tN&\tY&\tN&\tN& 5872 & 1&61 	&  5569 &  1&57\\
		\tY&\tN&\tN&\tN& 5689 & -1&56 	&  5481 &  -0&03\\
		\tN&\tN&\tN&\tN& 5884 & 1&81 	&  5505 &  0&41\\
	\end{tabular}\\[1em]

	\begin{tabular}{l p{0.65\linewidth}}
		\bfseries Key & \bfseries Option \\
		\hline
		X1 & \texttt{guess-branch-probability}  \\
		X2 & \texttt{tree-dominator-opts}  \\
		X3 & \texttt{tree-ch} \\
		X4 & \texttt{if-conversion} \\
		Abs (mJ) & Absolute energy measurement in millijoules \\
		\texttt{O1} (\%) & Percentage relative to \texttt{O1} \\
		\texttt{O2} (\%) & Percentage relative to \texttt{O2} \\
	\end{tabular}
	\caption{Data and Legend when exhaustively exploring 4 options compared to \texttt{O1} and \texttt{O2}. (Cortex-M3 with blowfish benchmark).}
	\label{Table:Exhaustive}
\end{table}




% talk about what the results are briefly
% second and third order interactions

\subsection{The Universality of Flags}

\todo{Todo: tie in with previous section about difficult of choosing options, variation seen on platforms. Possibly instruction set having a larger difference than architecture?}

An interesting problem for compiler designers is how to choose an optimal set of flags across different hardware platforms and applications. This section explores which individual flags had the largest effect in our experiments and establishes whether a set of consistently good optimizations are seen across each benchmark and platform. Table~\ref{Table:BestFlags} lists the results for this section, with the top three optimization flags (where that optimization has a larger average effect than 1\%) identified for each benchmark and platform combination.  Each letter represents an optimization that is labelled in the the table below. This table also specifies the number of times this flag occurs.

It can be seen that in many cases a similar set of options is seen for the same benchmark. Furthermore, only 20 out of 82 options (the number of flags enabled by \texttt{O1}, \texttt{O2} and \texttt{O3}) appear in the table. This adds weight to the argument that many of the options have little effect on the energy consumption (and performance).

From this is can be seen that the \texttt{-fomit-frame-pointer} flag is very effective at reducing the energy consumption. This is somewhat expected as this optimization frees up a register that would otherwise be used for the frame pointer where it is not needed. Closely following this option \texttt{-ftree-loop-optimize}.

Displaying the results in this way highlights some interesting correlations between platforms. The optimizer has trouble optimizing the crc32 benchmark, with the Cortex-M0 and Cortex-M3 only having one optimization which has any significant effects (\texttt{-fmove-loop-invariants}). The Cortex-A8 sees this platform having an effect, however this is still secondary to the previous optimization (it had an average of a 1.3\% effect on the energy consumption).

As mentioned in previous sections, similar options are seen to affect the energy consumption across benchmarks. This is due to the optimizations being targeted to specific high level language constructs, which only appear in some of the benchmarks.

\todo{Todo: Add long conclusions. why doesnt help with universality.}

\begin{table*}
	\centering
	\begin{tabular}{l >{\ttfamily} c >{\ttfamily} c >{\ttfamily} c >{\ttfamily} c }
		\bfseries Benchmark&\rmfamily\bfseries Cortex-M0&\rmfamily\bfseries Cortex-M3 & \rmfamily\bfseries Cortex-A8		& \rmfamily\bfseries Epiphany\\
		\hline
		2dfir          & E & T, G, H & N, G, C & H, A, D\\
		blowfish       & B, J, E & J, B, G & K, B, E & D, P, H\\
		crc32          & F & F & F, G & \\
		cubic          & A, I & A, I & A & A, I, O\\
		dijkstra       & I, A, B & F, I, A & F, I, A & \\
		fdct           & J, G, D & J, G, K & M, K, J & A, H, D\\
		float\_matmult & C, E & C, E, G & N, L & D, H, A\\
		int\_matmult   & C, E, B & C, L, F & L, N, M & A, H, D\\
		rijndael       &  & B, C, R & K, B, S & \\
		sha            & B, C, E & C, B, F & C, B, M & D, C, Q\\


	\end{tabular} \\[1em]

	\begin{tabular}{>{\fontsize{9}{1}\selectfont}c | r >{\ttfamily\fontsize{9}{1}\selectfont}l
					>{\fontsize{9}{1}\selectfont}c | r >{\ttfamily\fontsize{9}{1}\selectfont}l
					>{\fontsize{9}{1}\selectfont}c | r >{\ttfamily\fontsize{9}{1}\selectfont}l }
	\bfseries ID & \multicolumn{2}{l}{\bfseries Count\hspace{1.2cm}Flag} &\bfseries ID & \multicolumn{2}{l}{\bfseries  Count\hspace{1.2cm}Flag} &\bfseries ID & \multicolumn{2}{l}{\bfseries Count\hspace{1.2cm}Flag} \\
	\hline
	\fontsize{9}{1}\selectfont
	A & 11 & -ftree-dominator-opts &
	B & 10 & -fomit-frame-pointer &
	C & 10 & -ftree-loop-optimize \\
	D & 7  & -fdce &
	E & 7  & -fguess-branch-probability &
	F & 7  & -fmove-loop-invariants \\
	G & 7  & -ftree-ter &
	H & 6  & -ftree-ch &
	I & 6  & -ftree-fre \\
	J & 5  & -ftree-forwprop &
	K & 4  & -fschedule-insns &
	L & 3  & -finline-small-functions \\
	M & 3  & -fschedule-insns2 &
	N & 3  & -ftree-pre &
	O & 1  & -fcombine-stack-adjustments \\
	P & 1  & -fipa-profile &
	Q & 1  & -ftree-pta &
	R & 1  & -ftree-sra \\
	S & 1  & -fgcse  &
	T & 1  & -fpeephole2 &

	&&\\
	\end{tabular}

	\caption{Table showing the most effective option for each platform-benchmark combination. Options considered were
	optimizations enabled by \texttt{O1}, \texttt{O2} and \texttt{O3} levels.}
	\label{Table:BestFlags}
\end{table*}

\begin{figure*}
	\centering
    \begin{minipage}[l]{0.98\columnwidth}
        \centering
		\includegraphics[width=1.0\linewidth, clip, trim= 8.8cm 0 4.8cm 2cm]{cortex-m0/o1cub_-7p5_10.png}
        % \caption{AAA}\label{fig:AAA}
    \end{minipage}
    \hfill
    \begin{minipage}[l]{0.07\columnwidth}
        \centering
        \includegraphics[width=1.0\linewidth, clip, trim= 29.1cm 0 0cm 1.7cm]{cortex-m0/o1cub_-7p5_10.png}
        % \caption{AAA}\label{fig:AAA}
    \end{minipage}
    \hfill
    \begin{minipage}[r]{0.95\columnwidth}
        \centering
		\includegraphics[width=0.9\linewidth, clip, trim= 8.8cm 0 7cm 2cm]{cortex-m0/o1cub_-7p5_10_pred.png}
        % \caption{BBB}\label{fig:BBB}
    \end{minipage}
    \caption{Effect on execution time and energy consumption from turning on just two optimization flags at a time (all other options off). The actual result is shown on the left, and the prediction on the right.}
    \label{Fig:twoway_cubic}
\end{figure*}


\section{Modelling}

As mentioned earlier it is unlikely that a model exists that can predict how a set of optimizations will perform. However, if one were to be found, it would allow designers to make fast guesses about how their program will be optimized.

Given out previous conclusions regarding the difficulty of correlating optimizations against improvements, we would expect such a model to yeild only mediocre results. We wish to verify this hypothesis, since the construction of such a model that produces good results would serve to invalidate our previous conclusions. Our method was to construct a linear model using the data from the FFD. The resulting model fails to capture the higher order effects of some of the benchmarks. Figure~\ref{Fig:twoway_cubic} shows the cubic benchmark on the Cortex-M0 along with prediction, when pairs of optimizations are turned on. This shows the chaotic patterns that the constructed model was unable to capture.


\section{Discussion}

In this section, we explore any sources of error in our measurements and corresponding conclusions.
Using the FFD method allows a good estimate of the impact each compiler option has, while accounting for possible interactions between the options.

The hardware measurements itself have several sources of error. The most apparent errors are variations in the timing: the INA219 is polled at intervals of roughly 1~ms and the power measurement integrated over this. The interval is occasionally larger - the bottleneck was transferring the data over the communication link back to the PC. When many devices were simultaneously sending measurements the threads on the controller would stall to wait for the communication channel to become free, causing measurement intervals of up to 10ms. However this did not impact the results hugely as the energy integral over this time is largely similar, and each test was repeated multiple times to ensure consistent results.

There were other sources of error:
\begin{itemize}
	\item \textbf{ADC offset}. The ADC in the INA219 randomly fluctuated $\pm$30~$\mu$V. This could be compensated for by using a larger shunt resistor, so that this voltage change became insignificant.
	\item \textbf{Cold start problem}. The issue of what was in the instruction/data caches before a benchmark executed would change the execution time and energy profile of the test. Many investigations neglect to consider this basic factor, and it is important to discuss its impact in our results. The nature of many of the embedded platforms we examined is that caches are not present in any except for the BeagleBone, and so this factor is irrelevant. For the BeagleBone, the target benchmarks fitted entirely inside the cache. Whilst this does not stress the full memory hierarchy and explains a lack of variation in the memory subsystem results, it does present a level playing field and a fair comparison across the platforms.
\end{itemize}

% Talk about error
%  - hardware measurement
%  - total amonut of energy used is correct, even if sample rate is low
%  - FFD
%  - cold start problem
%  	only affects beaglebone, as no caches otherwise, but most fit in cache anyway


% Draw correlations between platforms and benchmarks.

% See if there is any correlation between the `execution characteristics' of the benchmark and the flags that affect it.

% Can we propose a set of options that on average performs better for the benchmarks?

% Why did we get these results

\section{What does this mean for the compiler writer?}

The existing collections of optimizations at the various levels (\texttt{O1}, etc.) do a good job of optimizing for performance, and consequently, energy. These strike a good balance between ease of use and performance. However, they will never be as optimal as searching through the full optimization space. Developing machine-learning compiler technologies similar to MILEPOST GCC would be ideal, because reasonable set of optimizations could be predicted, though this still requires a large amount of training data. This is especially true as the effectiveness and types of optimizations was found to be heavily based on the structure of the application being compiled itself. Implementing this would reduce compile times as well as the energy and execution time of the application.

This study concentrated on GCC, as it is a mature compiler supporting many different platforms and optimizations. The LLVM compiler is relatively new, but has a well defined set of optimization passes, whose order can easily be specified. This extra flexibility means there may be a better solution to find, but you are essentially searching for a sharper needle in a bigger haystack. The benefits from having this much larger space to explore may not be worth the trade-off of the time it takes to find it. Therefore, it is unlikely that we will ever be able to obtain the goal of easy optimization for run-time or energy, and will remain constrained to sub-optimal but balanced sets of flags such as \texttt{O3}.

% Finally, this work only explored applying optimizations as a whole to the benchmark. Applying options separately to different regions of code (such as on a per-function basis) could yield further results, at the cost of a much larger space to explore.

\section{Conclusion}

% \todo{most of the current optimizations in gcc reduce the total workload of the program. this in turn reduces the energy. if just energy reduction without performance gain is required, other optimizations will have to be implemented. the need for energy specific optimizations}

In this study we used fractional factorial design to explore the  execution time and energy consumption optimization space. We observe its effect on energy consumption and draw conclusions about what optimizations can an cannot provide global improvements in performance. In comparison to other methods such as iterative compilation, FFD is a good alternative because with a small number of runs the options affecting the energy consumption can be quickly found. We have refined the FFD methodology to allow the number of runs to be decreased further. This would allow more interactions to be resolved, with a higher overall level of accuracy.

We have shown that the assumption of no higher order compiler optimization interactions is incorrect. We substantiate this by showing the amount of variation seen between tests with different options enabled. In general, exploring the optimization space is time intensive and difficult to explore in a structured manner. Therefore, FFD and iterative techniques will always be necessary.

We have shown that in almost all cases the execution time and energy consumption of a benchmark are highly correlated, across five different platforms. Most of the current optimizations in GCC reduce the total workload of the program, which in turns reduces both the time and the energy. If energy reduction without a corresponding change in performance is required, other optimizations will have to be implemented.

% \todo{difficult to predict which optimizations will have an effect}
% \todo{many interactions between optimizations means that mostly the structure of the program input has a larger effect than the platform(?). 150 options, but even these consist of multiple passes. over 230 different passes in gcc}
It is very difficult to predict which optimizations will have an effect, whether that effect is positive, negative, or not impacting the benchmark at all. Among the options that do have an effect, there are many interactions. This results in a very chaotic space to explore, that empirically is affected more by the choice of benchmark than the platform it is running on. This highlights the importance of using more than one benchmark, and having that set of benchmarks cover different types of applications. In practical use, this means that no benchmark can be said to have similar optimizations to any related program, and the need for program-specific optimization will always exist. In this context, our refined low cost optimization exploration technique is all the more necessary.




% \todo{unlines the need for iterative compilation and techniques such as milepost}

% \todo{Very useful to have compiler optimizations decided by the features of the benchmark as optimization dont apply all the time, and by using a feature detect to match programs to optimizations would reduce compile time and increase efficiency.}

\section{Acknowledgements}

This work has been supported by funding from Embecosm\cite{Embecosm}. Development hardware provided by Adapteva\cite{Adapteva}.

\printbibliography

\end{document}


things to discuss
  some cases where omit-frame-pointer good, some bad
  sorting algorithms interesting
  cant predict
  lots of high level stuff - majority of cases time and energy correlated
    interesting where its not, but most of the time its a very small percentage that could easily be explained away
    no large optimizations which affect energy rather than execution time
